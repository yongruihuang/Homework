{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "import scipy.sparse as ss\n",
    "import warnings\n",
    "from six.moves import urllib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import abnormal_features_tools\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"attack_type\"]\n",
    "df_train = pd.read_csv('../data/train.data', names  = columns_name)\n",
    "# df_train.drop_duplicates(subset=None, inplace=True)\n",
    "df_test = pd.read_csv('../data/test.data', names  = columns_name)\n",
    "df_train['attack_type'] = df_train.attack_type.apply(lambda x:x[:-1])\n",
    "df_test['attack_type'] = df_test.attack_type.apply(lambda x:x[:-1])\n",
    "\n",
    "#map attack\n",
    "mp_attack_type = {'normal':'normal'}\n",
    "additional_attack = {'apache2':'dos', 'httptunnel':'r2l', 'mailbomb':'dos', 'mscan':'probe', 'named':'r2l', 'processtable':'dos', 'ps':'u2r', \n",
    "                    'saint':'probe', 'sendmail':'r2l', 'snmpgetattack':'r2l', 'snmpguess':'r2l', 'sqlattack':'u2r', 'udpstorm':'dos',\n",
    "                    'worm':'dos', 'xlock':'r2l', 'xsnoop':'r2l', 'xterm':'u2r'}\n",
    "with open('../data/training_attack_types') as f:\n",
    "    for line in f:\n",
    "        item = line.strip().split(' ')\n",
    "        mp_attack_type[item[0]] = item[1]\n",
    "        \n",
    "mp_attack_type.update(additional_attack)\n",
    "\n",
    "#map label\n",
    "df_train['attack_class'] = df_train.attack_type.apply(lambda x:mp_attack_type[x])\n",
    "df_test['attack_class'] = df_test.attack_type.apply(lambda x:mp_attack_type[x])\n",
    "\n",
    "# df_train = df_train[df_train.attack_class != 'dos']\n",
    "# df_test = df_test[df_test.attack_class != 'dos']\n",
    "\n",
    "df_train['label_attack_class'] = df_train.attack_class.apply(lambda x : {'normal':0, 'probe':1, 'dos':2, 'u2r':3, 'r2l':4}[x])\n",
    "df_test['label_attack_class'] = df_test.attack_class.apply(lambda x : {'normal':0, 'probe':1, 'dos':2, 'u2r':3, 'r2l':4}[x])\n",
    "symbolic_columns = ['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login']\n",
    "symbolic_features = ['feature_%s' % name for name in symbolic_columns]\n",
    "continuous_features = list(set(columns_name) - set(symbolic_columns) - set(['attack_type']))\n",
    "\n",
    "binary_cat_features = ['land', 'logged_in', 'is_host_login', 'is_guest_login']\n",
    "from category_encoders import *\n",
    "binary_encoder = BinaryEncoder()\n",
    "binary_encoder.fit(df_train[['protocol_type', 'flag', 'service']])\n",
    "df_binary_train = binary_encoder.transform(df_train[['protocol_type', 'flag', 'service']])\n",
    "df_binary_test = binary_encoder.transform(df_test[['protocol_type', 'flag', 'service']])\n",
    "used_features = continuous_features + binary_cat_features + list(df_binary_train.columns)\n",
    "\n",
    "df_train['is_attack'] = df_train.attack_class.apply(lambda x:x is not 'normal')\n",
    "df_test['is_attack'] = df_test.attack_class.apply(lambda x:x is not 'normal')\n",
    "\n",
    "df_train_used = pd.concat([df_train, df_binary_train], axis = 1)\n",
    "df_test_used = pd.concat([df_test, df_binary_test], axis = 1)\n",
    "\n",
    "df_train_attack_class = df_train_used[df_train.is_attack == True]\n",
    "df_test_attack_class = df_test_used[df_test.is_attack == True]\n",
    "\n",
    "for col_name, feature_name in zip(symbolic_columns, symbolic_features):\n",
    "    df_train[feature_name] = pd.factorize(df_train[col_name])[0]\n",
    "    df_test[feature_name] = pd.factorize(df_test[col_name])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution( df , var , target , **kwargs ):\n",
    "    row = kwargs.get( 'row' , None )\n",
    "    col = kwargs.get( 'col' , None )\n",
    "    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n",
    "    facet.map( sns.kdeplot , var , shade=True , cut=50)\n",
    "    facet.set( xlim=( 0 , df[ var ].max() ) )\n",
    "    facet.add_legend()\n",
    "\n",
    "def evaluate(ground_truth, predict):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print('All accuracy: %f' % accuracy_score(predict, ground_truth))\n",
    "\n",
    "    print('----------confusion_matrix-------------')\n",
    "    df_confusion_matrix = pd.DataFrame(confusion_matrix(ground_truth, predict))\n",
    "    display(HTML(df_confusion_matrix.to_html()))\n",
    "    \n",
    "    print('-------recall/fscore/f1 report---------')\n",
    "    df_precision_recall_fscore = pd.DataFrame(precision_recall_fscore_support(ground_truth, predict), index = ['precision', 'recall', 'f1', 'number'])\n",
    "    display(HTML(df_precision_recall_fscore.to_html()))\n",
    "    \n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def score(y_true, y_pred, show):\n",
    "    cost_matrix = [[0, 1, 2, 2, 2],\n",
    "                   [1, 0, 2, 2, 2],\n",
    "                   [2, 1, 0, 2, 2],\n",
    "                   [3, 2, 2, 0, 2],\n",
    "                   [4, 2, 2, 2, 0]\n",
    "                   ]\n",
    "    cost = 0\n",
    "    size = y_true.size\n",
    "    # print count & percentage matrix\n",
    "    if show:\n",
    "        count = [[0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 'x']\n",
    "                 ]\n",
    "        for i in range(size):\n",
    "            cost += cost_matrix[y_true[i]][y_pred[i]]  # y_ture should be dataframe.values\n",
    "            count[y_true[i]][y_pred[i]] += 1\n",
    "        for i in range(5):\n",
    "            if 0 == sum(count[i]):\n",
    "                count[i][5] = 0\n",
    "            else:\n",
    "                count[i][5] = count[i][i] / sum(count[i])\n",
    "        for i in range(5):\n",
    "            if 0 == sum(count[j][i] for j in range(5)):\n",
    "                count[5][i] = 0\n",
    "            else:\n",
    "                count[5][i] = count[i][i] / sum(count[j][i] for j in range(5))\n",
    "        print(\"-----------------------------------------------\")\n",
    "        for i in range(5):\n",
    "            print(\"%7d %7d %7d %7d %7d %1.5f\" % (\n",
    "                count[i][0], count[i][1], count[i][2], count[i][3], count[i][4], count[i][5]))\n",
    "        print(\"%1.5f %1.5f %1.5f %1.5f %1.5f\" % (\n",
    "            count[5][0], count[5][1], count[5][2], count[5][3], count[5][4]))\n",
    "        print(\"score: \", cost / size)\n",
    "        print(\"-----------------------------------------------\")\n",
    "    else:\n",
    "        for i in range(size):\n",
    "            cost += cost_matrix[y_true[i]][y_pred[i]]\n",
    "    return cost / size\n",
    "\n",
    "\n",
    "def scorer(show):\n",
    "    return make_scorer(score, show=show, greater_is_better=False)\n",
    "    \n",
    "    \n",
    "def print_mean(df, feature_name):\n",
    "    mean_value = df[feature_name].mean(), df[df['attack_class'] == 'normal'][feature_name].mean(), \\\n",
    "    df[df['attack_class'] == 'u2r'][feature_name].mean(), df[df['attack_class'] == 'dos'][feature_name].mean(), \\\n",
    "    df[df['attack_class'] == 'r2l'][feature_name].mean(), \\\n",
    "    df[df['attack_class'] == 'probe'][feature_name].mean()\n",
    "    attack_tpye = ['All', 'normal', 'u2r', 'dos', 'r2l', 'probe']\n",
    "\n",
    "    df = pd.DataFrame(list(mean_value), index = attack_tpye)\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "def train_eval_DT(train_X, train_y, test_X, test_y):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "#     clf = DecisionTreeClassifier(random_state=0, max_depth = 3)\n",
    "    count_num = np.bincount(train_y)\n",
    "    clf = DecisionTreeClassifier(random_state=0, class_weight = 'balanced')\n",
    "\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    print('cost time : %f' % (time.time() - start))\n",
    "    \n",
    "    dt_score = clf.predict_proba(test_X)\n",
    "\n",
    "    dt_predict = np.argmax(dt_score, axis = 1)\n",
    "\n",
    "    evaluate(test_y, dt_predict)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重要特征寻找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def feature_select(origin_features, n, df_features, target):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    found_features = []\n",
    "    for _ in range(n):\n",
    "        left_features = list(set(origin_features) - set(found_features))\n",
    "        clf = DecisionTreeClassifier(random_state=0, max_depth  = 2)\n",
    "        clf.fit(df_features[left_features], target)\n",
    "        max_idx = np.argmax(clf.feature_importances_)\n",
    "        found_features.append(left_features[max_idx])\n",
    "    \n",
    "    return found_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dos = df_train_used['attack_class'] == 'dos'\n",
    "target_normal = df_train_used['attack_class'] == 'normal'\n",
    "target_probe = df_train_used['attack_class'] == 'probe'\n",
    "target_u2r = df_train_used['attack_class'] == 'u2r'\n",
    "target_r2l = df_train_used['attack_class'] == 'r2l'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dos_features = feature_select(used_features, 4, df_train_used, target_dos)\n",
    "normal_features = feature_select(used_features, 4, df_train_used, target_normal)\n",
    "probe_features = feature_select(used_features, 4, df_train_used, target_probe)\n",
    "u2r_features = feature_select(used_features, 4, df_train_used, target_u2r)\n",
    "r2l_features = feature_select(used_features, 4, df_train_used, target_r2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dst_bytes', 'duration', 'src_bytes', 'hot']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2l_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormal feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_used['type'] = 'train'\n",
    "df_test_used['type'] = 'test'\n",
    "X = pd.concat([df_train_used, df_test_used], axis = 0)\n",
    "X.index = range(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525.739902973175\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "ifo_para = [ 150, ]\n",
    "start = time.time()\n",
    "feature_names, probe_abnormal_features_ifo = abnormal_features_tools.get_TOS_iforest(X[probe_features], ifo_para)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.9950156211853\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "ifo_para = [ 15, ]\n",
    "start = time.time()\n",
    "feature_names, u2r_abnormal_features_ifo = abnormal_features_tools.get_TOS_iforest(X[u2r_features], ifo_para)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.01590585708618\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "ifo_para = [ 64, ]\n",
    "start = time.time()\n",
    "feature_names, r2l_abnormal_features_ifo = abnormal_features_tools.get_TOS_iforest(X[r2l_features], ifo_para)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.195741653442383\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hobs_para = [1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250]\n",
    "hobs_para = [50]\n",
    "\n",
    "feature_list, probe_abnormal_features_hobs = abnormal_features_tools.get_TOS_hbos(X[probe_features].values, hobs_para)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.46952724456787\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hobs_para = [1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250]\n",
    "hobs_para = [50]\n",
    "\n",
    "feature_list, u2r_abnormal_features_ifo = abnormal_features_tools.get_TOS_hbos(X[u2r_features].values, hobs_para)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.332566022872925\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hobs_para = [1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250]\n",
    "hobs_para = [50]\n",
    "\n",
    "feature_list, r2l_abnormal_features_ifo = abnormal_features_tools.get_TOS_hbos(X[r2l_features].values, hobs_para)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['probe_abnormal_features_ifo'] = probe_abnormal_features_ifo\n",
    "X['u2r_abnormal_features_ifo'] = u2r_abnormal_features_ifo\n",
    "X['r2l_abnormal_features_ifo'] = r2l_abnormal_features_ifo\n",
    "X['probe_abnormal_features_hobs'] = probe_abnormal_features_hobs\n",
    "X['u2r_abnormal_features_hobs'] = u2r_abnormal_features_ifo\n",
    "X['r2l_abnormal_features_hobs'] = r2l_abnormal_features_ifo\n",
    "abnormal_features = ['probe_abnormal_features_ifo', 'u2r_abnormal_features_ifo', 'r2l_abnormal_features_ifo', 'probe_abnormal_features_hobs',\n",
    "                    'u2r_abnormal_features_hobs', 'r2l_abnormal_features_hobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    252816\n",
       "True      58213\n",
       "Name: probe_abnormal_features_ifo, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.iloc[df_train_used.shape[0]:]['probe_abnormal_features_ifo'] > 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All accuracy: 0.944735\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293829</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16334</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.947337</td>\n",
       "      <td>0.012702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.997099</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.971581</td>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>294684.000000</td>\n",
       "      <td>16345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate(target_all.iloc[df_train_used.shape[0]:] == 4, X.iloc[df_train_used.shape[0]:]['r2l_abnormal_features_hobs'] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos       3883370\n",
       "normal     972781\n",
       "probe       41102\n",
       "r2l          1126\n",
       "u2r            52\n",
       "Name: attack_class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_used['attack_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos       229855\n",
       "normal     60593\n",
       "r2l        16345\n",
       "probe       4166\n",
       "u2r           70\n",
       "Name: attack_class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_used['attack_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dos = X['attack_class'] == 'dos'\n",
    "target_normal = X['attack_class'] == 'normal'\n",
    "target_probe = X['attack_class'] == 'probe'\n",
    "target_r2l = X['attack_class'] == 'r2l'\n",
    "target_u2r = X['attack_class'] == 'u2r'\n",
    "target_all = X['label_attack_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 30.424705\n",
      "All accuracy: 0.923830\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>438</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>490</td>\n",
       "      <td>3227</td>\n",
       "      <td>449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5618</td>\n",
       "      <td>189</td>\n",
       "      <td>224048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15879</td>\n",
       "      <td>401</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.731300</td>\n",
       "      <td>0.758402</td>\n",
       "      <td>0.997307</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.990230</td>\n",
       "      <td>0.774604</td>\n",
       "      <td>0.974736</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.003243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.841293</td>\n",
       "      <td>0.766417</td>\n",
       "      <td>0.985892</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.006463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>60593.000000</td>\n",
       "      <td>4166.000000</td>\n",
       "      <td>229855.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>16345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_y = X[used_features + abnormal_features].iloc[:df_train_used.shape[0]], target_all.iloc[:df_train_used.shape[0]]\n",
    "test_X, test_y = X[used_features + abnormal_features].iloc[df_train_used.shape[0]:], target_all.iloc[df_train_used.shape[0]:]\n",
    "clf_DT_all = train_eval_DT(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 36.121006\n",
      "All accuracy: 0.977584\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80941</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6739</td>\n",
       "      <td>223116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.923141</td>\n",
       "      <td>0.998957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.997130</td>\n",
       "      <td>0.970682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.984616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>81174.000000</td>\n",
       "      <td>229855.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_y = X[used_features + abnormal_features].iloc[:df_train_used.shape[0]], target_dos.iloc[:df_train_used.shape[0]]\n",
    "test_X, test_y = X[used_features + abnormal_features].iloc[df_train_used.shape[0]:], target_dos.iloc[df_train_used.shape[0]:]\n",
    "clf_DT_dos = train_eval_DT(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 40.022022\n",
      "All accuracy: 0.926589\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228261</td>\n",
       "      <td>22175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658</td>\n",
       "      <td>59935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.997126</td>\n",
       "      <td>0.729935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.911454</td>\n",
       "      <td>0.989141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.952367</td>\n",
       "      <td>0.839996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>250436.000000</td>\n",
       "      <td>60593.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_y = X[used_features + abnormal_features].iloc[:df_train_used.shape[0]], target_normal.iloc[:df_train_used.shape[0]]\n",
    "test_X, test_y = X[used_features + abnormal_features].iloc[df_train_used.shape[0]:], target_normal.iloc[df_train_used.shape[0]:]\n",
    "clf_DT_normal = train_eval_DT(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 38.401389\n",
      "All accuracy: 0.994711\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>306236</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.996687</td>\n",
       "      <td>0.833907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.997957</td>\n",
       "      <td>0.755641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.792847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>306863.000000</td>\n",
       "      <td>4166.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_y = X[used_features + abnormal_features].iloc[:df_train_used.shape[0]], target_probe.iloc[:df_train_used.shape[0]]\n",
    "test_X, test_y = X[used_features + abnormal_features].iloc[df_train_used.shape[0]:], target_probe.iloc[df_train_used.shape[0]:]\n",
    "clf_DT_probe = train_eval_DT(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 18.068490\n",
      "All accuracy: 0.948757\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294677</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15931</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.948710</td>\n",
       "      <td>0.983373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.025329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.973669</td>\n",
       "      <td>0.049386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>294684.000000</td>\n",
       "      <td>16345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_y = X[used_features + abnormal_features].iloc[:df_train_used.shape[0]], target_r2l.iloc[:df_train_used.shape[0]]\n",
    "test_X, test_y = X[used_features + abnormal_features].iloc[df_train_used.shape[0]:], target_r2l.iloc[df_train_used.shape[0]:]\n",
    "clf_DT_r2l = train_eval_DT(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 7.728306\n",
      "All accuracy: 0.999791\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310949</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>310959.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_y = X[used_features + abnormal_features].iloc[:df_train_used.shape[0]], target_u2r.iloc[:df_train_used.shape[0]]\n",
    "test_X, test_y = X[used_features + abnormal_features].iloc[df_train_used.shape[0]:], target_u2r.iloc[df_train_used.shape[0]:]\n",
    "clf_DT_u2r = train_eval_DT(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mergeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = X[used_features + abnormal_features].iloc[df_train_used.shape[0]:]\n",
    "predict = np.zeros(test_y.shape[0]) - 1\n",
    "\n",
    "dos_score = clf_DT_dos.predict_proba(test_X)[:, 1]\n",
    "predict[np.where(dos_score > 0.5)] = 2\n",
    "\n",
    "normal_score = clf_DT_normal.predict_proba(test_X)[:, 1]\n",
    "predict[np.where(normal_score > 0.5)] = 0\n",
    "\n",
    "probe_score = clf_DT_probe.predict_proba(test_X)[:, 1]\n",
    "predict[np.where(probe_score > 0.5)] = 1\n",
    "\n",
    "r2l_score = clf_DT_r2l.predict_proba(test_X)[:, 1]\n",
    "predict[np.where(r2l_score > 0.5)] = 4\n",
    "\n",
    "u2r_score = clf_DT_u2r.predict_proba(test_X)[:, 1]\n",
    "predict[np.where(u2r_score > 0.5)] = 3\n",
    "\n",
    "predict[predict == -1] = clf_DT_all.predict(test_X.iloc[np.where(predict == -1)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最终效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All accuracy: 0.924634\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60037</td>\n",
       "      <td>492</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631</td>\n",
       "      <td>3353</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5866</td>\n",
       "      <td>221</td>\n",
       "      <td>223768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15596</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.730537</td>\n",
       "      <td>0.762912</td>\n",
       "      <td>0.998933</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.988067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.990824</td>\n",
       "      <td>0.804849</td>\n",
       "      <td>0.973518</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.025329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.841002</td>\n",
       "      <td>0.783320</td>\n",
       "      <td>0.986062</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>60593.000000</td>\n",
       "      <td>4166.000000</td>\n",
       "      <td>229855.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>16345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate(target_all.iloc[df_train_used.shape[0]:], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5986218"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.841002 + 0.783320 + 0.986062 + 0.333333 + 0.049392) / 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5986216021592836"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(target_all.iloc[df_train_used.shape[0]:], predict, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline 模型对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time : 27.936640\n",
      "All accuracy: 0.923496\n",
      "----------confusion_matrix-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60241</td>\n",
       "      <td>247</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>819</td>\n",
       "      <td>3173</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5864</td>\n",
       "      <td>205</td>\n",
       "      <td>223786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15787</td>\n",
       "      <td>527</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------recall/fscore/f1 report---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.727865</td>\n",
       "      <td>0.764210</td>\n",
       "      <td>0.998786</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.994191</td>\n",
       "      <td>0.761642</td>\n",
       "      <td>0.973596</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.840433</td>\n",
       "      <td>0.762924</td>\n",
       "      <td>0.986030</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>60593.000000</td>\n",
       "      <td>4166.000000</td>\n",
       "      <td>229855.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>16345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_y = X[used_features].iloc[:df_train_used.shape[0]], target_all.iloc[:df_train_used.shape[0]]\n",
    "test_X, test_y = X[used_features].iloc[df_train_used.shape[0]:], target_all.iloc[df_train_used.shape[0]:]\n",
    "clf_DT_all_origin_features = train_eval_DT(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5639179999999999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.840433 + 0.762924 + 0.986030 + 0.227273 + 0.002930) / 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_origin_feature = clf_DT_all_origin_features.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5639180477291231"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(target_all.iloc[df_train_used.shape[0]:], predict_origin_feature, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
