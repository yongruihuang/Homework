{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "with open('../data/comment_with_entity.json', 'r') as f:\n",
    "    for line in f:\n",
    "        comments.append(json.loads(line.strip()))\n",
    "movies = []\n",
    "with open('../data/movie_with_entity.json', 'r') as f:\n",
    "    for line in f:\n",
    "        movies.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2776, 1102111)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies), len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2776, 1102111)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies), len(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PER，LOC，ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 数据简单清洗去重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 评论去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comment_set = set()\n",
    "comment_clean = []\n",
    "for comment in comments:\n",
    "    if comment['comment_text'] is None:\n",
    "        continue\n",
    "    unique_hash_comment = str(comment['comment_text']) + str(comment['user_url'])\n",
    "    if unique_hash_comment in comment_set:\n",
    "        continue\n",
    "    comment_clean.append(comment)\n",
    "    comment_set.add(unique_hash_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movie_url_set = set()\n",
    "for comment in comment_clean:\n",
    "    movie_url_set.add(comment['movie_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 电影去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "have_url_set = set()\n",
    "movie_name_set = set()\n",
    "movie_clean = []\n",
    "for movie in movies:\n",
    "\n",
    "    if movie['movie_url'] in movie_url_set and movie['movie_url'] not in have_url_set and movie['title'] not in movie_name_set:\n",
    "        movie_clean.append(movie)\n",
    "        have_url_set.add(movie['movie_url'])\n",
    "        movie_name_set.add(movie['title'])\n",
    "        if(u'魔鬼悍将' in movie['title']):\n",
    "            print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2776, 2776)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_clean), len(movie_url_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102111, 1102111)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments), len(comment_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 重新写入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../data/comments_clean.json', 'w', encoding='utf-8') as f:\n",
    "    for comment in comment_clean:\n",
    "        f.write(json.dumps(comment, ensure_ascii=False))\n",
    "        f.write('\\n')\n",
    "        \n",
    "with open('../data/movies_clean.json', 'w', encoding='utf-8') as f:\n",
    "    for movie in movie_clean:\n",
    "        f.write(json.dumps(movie, ensure_ascii=False))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 样本构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_movie_comments = {}\n",
    "for comment in comments:\n",
    "    comment_list = mp_movie_comments.get(comment['movie_url'], 0)\n",
    "    if(comment_list is 0):\n",
    "        mp_movie_comments[comment['movie_url']] = [comment,]\n",
    "    else:\n",
    "        mp_movie_comments[comment['movie_url']].append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.048156023025512695\n",
      "100 1.157289981842041\n",
      "150 1.1889243125915527\n",
      "200 1.220710039138794\n",
      "250 1.2514405250549316\n",
      "300 1.282799482345581\n",
      "350 1.3131978511810303\n",
      "400 1.3434629440307617\n",
      "450 1.3742926120758057\n",
      "500 1.4060022830963135\n",
      "550 1.436755657196045\n",
      "600 1.4677681922912598\n",
      "650 1.4988353252410889\n",
      "700 2.6190783977508545\n",
      "750 2.6506636142730713\n",
      "800 2.6814792156219482\n",
      "850 2.711899518966675\n",
      "900 2.742671251296997\n",
      "950 2.773435354232788\n",
      "1000 2.803821563720703\n",
      "1050 2.834181308746338\n",
      "1100 2.8642959594726562\n",
      "1150 2.8928608894348145\n",
      "1200 2.922450542449951\n",
      "1250 2.953110694885254\n",
      "1300 2.98323130607605\n",
      "1350 3.0128819942474365\n",
      "1400 3.0426251888275146\n",
      "1450 4.326707363128662\n",
      "1500 4.356860160827637\n",
      "1550 4.387431859970093\n",
      "1600 4.418727397918701\n",
      "1650 4.44938850402832\n",
      "1700 4.48021388053894\n",
      "1750 4.511022090911865\n",
      "1800 4.5416858196258545\n",
      "1850 4.5721635818481445\n",
      "1900 4.603025674819946\n",
      "1950 4.633539438247681\n",
      "2000 4.664257526397705\n",
      "2050 4.695501089096069\n",
      "2100 4.725247859954834\n",
      "2150 4.754871606826782\n",
      "2200 4.785121202468872\n",
      "2250 4.815282583236694\n",
      "2300 4.845842123031616\n",
      "2350 4.876644611358643\n",
      "2400 6.2429022789001465\n",
      "2450 6.272907733917236\n",
      "2500 6.302403450012207\n",
      "2550 6.331997632980347\n",
      "2600 6.361539840698242\n",
      "2650 6.389743089675903\n",
      "2700 6.417627334594727\n",
      "2750 6.445897579193115\n",
      "6.4611968994140625\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "sample_movie_num = 2\n",
    "sample_comment_num = 32\n",
    "use_movie_comment_num = 16\n",
    "cnt = 1\n",
    "start = time.time()\n",
    "for movie in movies:\n",
    "    movie_url = movie['movie_url']\n",
    "    if(mp_movie_comments.get(movie_url, 0) is 0):\n",
    "        continue\n",
    "    other_movies = random.sample(movies, sample_movie_num)\n",
    "    other_comments = []\n",
    "    for other_movie in other_movies:\n",
    "        other_url = other_movie['movie_url']\n",
    "        if other_url == movie_url:\n",
    "            continue\n",
    "        if(mp_movie_comments.get(other_url, 0) is 0):\n",
    "            continue\n",
    "        other_comments.extend(mp_movie_comments[other_url][-sample_comment_num:])\n",
    "    for comment in mp_movie_comments[movie_url][:use_movie_comment_num]:\n",
    "        for other_comment in other_comments:\n",
    "            a_sample = {}\n",
    "            a_sample['movie'] = movie\n",
    "            a_sample['right_comment'] = comment\n",
    "            a_sample['wrong_comment'] = other_comment\n",
    "            samples.append(a_sample)\n",
    "    cnt += 1\n",
    "    if(cnt % 50 == 0):\n",
    "        print(cnt, time.time() - start)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2842112"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': {'score': '7.6',\n",
       "  'title': '\\n钢铁侠2 Iron Man 2\\n(2010)\\n',\n",
       "  'summary': '钢铁侠托尼·斯塔克（小罗伯特·唐尼 Robert Downey Jr. 饰）在国会听证上拒绝交出最新技术。与此同时，他发现胸口的微型电弧反应炉正迅速造成血液的钯金属中毒。沮丧的托尼将斯塔克公司的总裁职务交予了秘书波兹（格温妮丝·帕特罗 Gwyneth Paltrow 饰），由她全权负责正在进行的纽约斯塔克博览会。波兹从法律部门调来助理娜塔莉（斯佳丽·约翰逊 Scarlett Johansson 饰）照顾托尼。托尼在媒体前的高调亮相引起了其父当年同事的儿子，伊凡（米基·洛克 Mickey Rourke 饰）的不满。为了实施报复，他子承父业，研制出了一套可与钢铁战衣相媲美的装备。伊凡的技术引起了托尼的竞争对手，军火商贾斯丁·汉默（山姆·洛克威尔 Sam Rockwell 饰）的注意，他设法将伊凡劫持出狱，秘密研究取代钢铁侠。正当托尼苦于钯金属中毒造成的失...',\n",
       "  'directors': ['乔恩·费儒'],\n",
       "  'writer': ['贾斯汀·塞洛克斯'],\n",
       "  'actor': ['小罗伯特·唐尼',\n",
       "   '格温妮斯·帕特洛',\n",
       "   '米基·洛克',\n",
       "   '斯嘉丽·约翰逊',\n",
       "   '山姆·洛克威尔',\n",
       "   '唐·钱德尔',\n",
       "   '塞缪尔·杰克逊',\n",
       "   '乔恩·费儒',\n",
       "   '保罗·贝坦尼',\n",
       "   '克拉克·格雷格',\n",
       "   '凯特·玛拉',\n",
       "   '约翰·斯拉特里'],\n",
       "  'country': ' 美国',\n",
       "  'minutes': '124 分钟',\n",
       "  'type': ['动作', '科幻', '冒险'],\n",
       "  'releasedDate': ['2010-05-07(中国大陆/美国)'],\n",
       "  'recommended_urls': ['https://movie.douban.com/subject/1432146/',\n",
       "   'https://movie.douban.com/subject/1432146/',\n",
       "   'https://movie.douban.com/subject/10741834/',\n",
       "   'https://movie.douban.com/subject/10741834/',\n",
       "   'https://movie.douban.com/subject/2138838/',\n",
       "   'https://movie.douban.com/subject/2138838/',\n",
       "   'https://movie.douban.com/subject/1866475/',\n",
       "   'https://movie.douban.com/subject/1866475/',\n",
       "   'https://movie.douban.com/subject/1866471/',\n",
       "   'https://movie.douban.com/subject/1866471/',\n",
       "   'https://movie.douban.com/subject/1866473/',\n",
       "   'https://movie.douban.com/subject/1866473/',\n",
       "   'https://movie.douban.com/subject/1401524/',\n",
       "   'https://movie.douban.com/subject/1401524/',\n",
       "   'https://movie.douban.com/subject/1792928/',\n",
       "   'https://movie.douban.com/subject/1792928/',\n",
       "   'https://movie.douban.com/subject/1794171/',\n",
       "   'https://movie.douban.com/subject/1794171/',\n",
       "   'https://movie.douban.com/subject/7065154/',\n",
       "   'https://movie.douban.com/subject/7065154/'],\n",
       "  'collected_num': '42195',\n",
       "  'wish_num': '943',\n",
       "  'movie_url': 'https://movie.douban.com/subject/3066739/',\n",
       "  'entities': ['托尼·斯塔克 PER',\n",
       "   '罗伯特·唐尼rober PER',\n",
       "   '国会 ORG',\n",
       "   '托尼 PER',\n",
       "   '斯塔克公司 ORG',\n",
       "   '波兹 PER',\n",
       "   '格温妮丝·帕特罗 PER']},\n",
       " 'right_comment': {'user_url': 'https://www.douban.com/people/dahuoji/',\n",
       "  'comment_text': '约翰森真酷',\n",
       "  'votes': '1',\n",
       "  'star': '4',\n",
       "  'comment_time': '2010-05-14 22:40:21',\n",
       "  'watch_type': '看过',\n",
       "  'rank': 12,\n",
       "  'comment_id': 812,\n",
       "  'movie_url': 'https://movie.douban.com/subject/3066739/',\n",
       "  'entities': ['约翰森 PER']},\n",
       " 'wrong_comment': {'user_url': 'https://www.douban.com/people/38279985/',\n",
       "  'comment_text': '棒子版《我是传奇》+《雪国列车》。。。悲壮的逃生釜山行',\n",
       "  'votes': '1',\n",
       "  'star': '3',\n",
       "  'comment_time': '2016-09-13 00:21:46',\n",
       "  'watch_type': '看过',\n",
       "  'rank': 398,\n",
       "  'comment_id': 270558,\n",
       "  'movie_url': 'https://movie.douban.com/subject/25986180/',\n",
       "  'entities': ['雪国 LOC', '釜山 LOC']}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[2781]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def build_tfidf_svd_matrix(texts, n_output):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    for text in texts:\n",
    "        words = word_segment(str(text))\n",
    "        use_words = []\n",
    "        for word in words:\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                use_words.append(word)\n",
    "        corpus.append(' '.join(use_words))\n",
    "    tfidf_vec = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vec.fit_transform(corpus)\n",
    "    svd = TruncatedSVD(n_components=n_output, n_iter=7, random_state=42)\n",
    "    tf_idf_svd = svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    return tf_idf_svd, tfidf_vec, svd\n",
    "\n",
    "\n",
    "def word_segment(sentence):\n",
    "    words = jieba.cut(sentence)\n",
    "    return ','.join(words).split(',')\n",
    "\n",
    "stop_words = set()\n",
    "def load_stopwords():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open('../middle_data/stopwords.txt', 'r', encoding='UTF-8') as f:\n",
    "        for line in f.readlines():\n",
    "            stop_words.add(line.strip())\n",
    "\n",
    "load_stopwords()\n",
    "\n",
    "def remove_stopwords(word_lists):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for word in word_lists:\n",
    "        if word not in stop_words:\n",
    "            res.append(word)\n",
    "    return ' '.join(res)\n",
    "\n",
    "def clean_text(string):\n",
    "    return string.replace(' ', '').replace('\\n', '').replace('\\u3000', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_types = set()\n",
    "for movie in movies:\n",
    "    for movie_type in movie['type']:\n",
    "        movie_types.add(movie_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_features = []\n",
    "movie_features.extend(list(movie_types))\n",
    "hand_select_features = ['len_directors', 'len_writer', 'len_actor', 'len_title', 'len_summary']\n",
    "movie_features.extend(hand_select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../middle_data/movie_features.sk.var']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(movie_features, '../middle_data/movie_features.sk.var')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.DataFrame(np.zeros((len(movies), len(movie_features))), columns = movie_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "def set_features(x):\n",
    "    global cnt\n",
    "    movie = movies[cnt]\n",
    "    cnt += 1\n",
    "    x[movie['type']] = 1\n",
    "    x['len_directors'] = len(movie['directors'])\n",
    "    x['len_writer'] = len(movie['writer'])    \n",
    "    x['len_actor'] = len(movie['actor'])    \n",
    "    x['len_title'] = len(clean_text(movie['title']))\n",
    "    x['len_summary'] = len(clean_text(movie['summary']))\n",
    "_ = df_movies.apply(set_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>武侠</th>\n",
       "      <th>儿童</th>\n",
       "      <th>西部</th>\n",
       "      <th>爱情</th>\n",
       "      <th>同性</th>\n",
       "      <th>喜剧</th>\n",
       "      <th>犯罪</th>\n",
       "      <th>恐怖</th>\n",
       "      <th>奇幻</th>\n",
       "      <th>科幻</th>\n",
       "      <th>...</th>\n",
       "      <th>剧情</th>\n",
       "      <th>战争</th>\n",
       "      <th>黑色电影</th>\n",
       "      <th>历史</th>\n",
       "      <th>家庭</th>\n",
       "      <th>len_directors</th>\n",
       "      <th>len_writer</th>\n",
       "      <th>len_actor</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       武侠   儿童   西部   爱情   同性   喜剧   犯罪   恐怖   奇幻   科幻  ...   剧情   战争  黑色电影  \\\n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  ...  0.0  0.0   0.0   \n",
       "5     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   0.0   \n",
       "6     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "2604  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   0.0   \n",
       "2616  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0   0.0   \n",
       "2632  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   0.0   \n",
       "2637  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0   0.0   \n",
       "2639  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0   0.0   \n",
       "\n",
       "       历史   家庭  len_directors  len_writer  len_actor  len_title  len_summary  \n",
       "2     0.0  0.0            1.0         1.0       12.0       18.0        367.0  \n",
       "3     0.0  0.0            2.0         2.0       20.0       42.0        351.0  \n",
       "4     0.0  0.0            1.0         3.0       25.0       37.0        358.0  \n",
       "5     0.0  0.0            1.0         1.0        5.0       27.0        368.0  \n",
       "6     0.0  0.0            1.0         7.0       23.0       15.0        260.0  \n",
       "...   ...  ...            ...         ...        ...        ...          ...  \n",
       "2604  0.0  0.0            1.0         1.0       18.0       21.0        238.0  \n",
       "2616  0.0  0.0            1.0         2.0       13.0       20.0        348.0  \n",
       "2632  0.0  0.0            1.0         2.0       15.0       29.0        373.0  \n",
       "2637  0.0  0.0            3.0         1.0       12.0       32.0         56.0  \n",
       "2639  0.0  0.0            1.0         1.0        9.0       27.0         85.0  \n",
       "\n",
       "[394 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies[df_movies['科幻'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_texts = []\n",
    "for movie in movies:\n",
    "    text = clean_text(movie['title'] + movie['summary'])\n",
    "    movie_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.857 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "movie_texts_tfidf_svd, tfidf_vec_movie, svd_movie = build_tfidf_svd_matrix(movie_texts, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../middle_data/svd_movie.sk.model']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(tfidf_vec_movie, '../middle_data/tfidf_vec_movie.sk.model')\n",
    "dump(svd_movie, '../middle_data/svd_movie.sk.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_movie_columns_names = ['td_idf_movie_%d' % i for i in range(movie_texts_tfidf_svd.shape[1])]\n",
    "df_tf_idf_movie_svd = pd.DataFrame(movie_texts_tfidf_svd, columns = tf_idf_movie_columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>武侠</th>\n",
       "      <th>儿童</th>\n",
       "      <th>西部</th>\n",
       "      <th>爱情</th>\n",
       "      <th>同性</th>\n",
       "      <th>喜剧</th>\n",
       "      <th>犯罪</th>\n",
       "      <th>恐怖</th>\n",
       "      <th>奇幻</th>\n",
       "      <th>科幻</th>\n",
       "      <th>...</th>\n",
       "      <th>td_idf_movie_54</th>\n",
       "      <th>td_idf_movie_55</th>\n",
       "      <th>td_idf_movie_56</th>\n",
       "      <th>td_idf_movie_57</th>\n",
       "      <th>td_idf_movie_58</th>\n",
       "      <th>td_idf_movie_59</th>\n",
       "      <th>td_idf_movie_60</th>\n",
       "      <th>td_idf_movie_61</th>\n",
       "      <th>td_idf_movie_62</th>\n",
       "      <th>td_idf_movie_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017530</td>\n",
       "      <td>0.041538</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>-0.026284</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.021619</td>\n",
       "      <td>0.041345</td>\n",
       "      <td>-0.051655</td>\n",
       "      <td>0.044011</td>\n",
       "      <td>-0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.033202</td>\n",
       "      <td>-0.018139</td>\n",
       "      <td>-0.026845</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.032574</td>\n",
       "      <td>-0.021791</td>\n",
       "      <td>0.023361</td>\n",
       "      <td>-0.017838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039166</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>0.049353</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>-0.059249</td>\n",
       "      <td>-0.008669</td>\n",
       "      <td>0.037422</td>\n",
       "      <td>-0.023646</td>\n",
       "      <td>-0.013603</td>\n",
       "      <td>0.019573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.005642</td>\n",
       "      <td>0.051554</td>\n",
       "      <td>-0.097415</td>\n",
       "      <td>-0.032493</td>\n",
       "      <td>-0.016136</td>\n",
       "      <td>0.043008</td>\n",
       "      <td>-0.024096</td>\n",
       "      <td>-0.021270</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.085970</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.092546</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.058371</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>0.047687</td>\n",
       "      <td>-0.050658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    武侠   儿童   西部   爱情   同性   喜剧   犯罪   恐怖   奇幻   科幻  ...  td_idf_movie_54  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...        -0.017530   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...         0.011432   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...         0.039166   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...        -0.000834   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  ...         0.019182   \n",
       "\n",
       "   td_idf_movie_55  td_idf_movie_56  td_idf_movie_57  td_idf_movie_58  \\\n",
       "0         0.041538         0.003458        -0.026284         0.014450   \n",
       "1         0.033202        -0.018139        -0.026845         0.008995   \n",
       "2         0.009165         0.049353         0.004273        -0.059249   \n",
       "3        -0.005642         0.051554        -0.097415        -0.032493   \n",
       "4         0.085970         0.009967        -0.092546        -0.057068   \n",
       "\n",
       "   td_idf_movie_59  td_idf_movie_60  td_idf_movie_61  td_idf_movie_62  \\\n",
       "0         0.021619         0.041345        -0.051655         0.044011   \n",
       "1         0.018500         0.032574        -0.021791         0.023361   \n",
       "2        -0.008669         0.037422        -0.023646        -0.013603   \n",
       "3        -0.016136         0.043008        -0.024096        -0.021270   \n",
       "4        -0.058371         0.014235         0.011969         0.047687   \n",
       "\n",
       "   td_idf_movie_63  \n",
       "0        -0.007605  \n",
       "1        -0.017838  \n",
       "2         0.019573  \n",
       "3         0.001998  \n",
       "4        -0.050658  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies_with_tfidf = pd.concat([df_movies, df_tf_idf_movie_svd], axis=1)\n",
    "df_movies_with_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 是否归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = df_movies_with_tfidf[hand_select_features].mean()\n",
    "std = df_movies_with_tfidf[hand_select_features].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_all_normal = df_movies_with_tfidf.copy()\n",
    "df_movies_all_normal[hand_select_features] = (df_movies_all_normal[hand_select_features] - X_mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_movie_url_vector = {}\n",
    "for i in range(len(movies)):\n",
    "    mp_movie_url_vector[movies[i]['movie_url']] = np.array(df_movies_with_tfidf.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_url': 'https://www.douban.com/people/questwoo/',\n",
       " 'comment_text': '我能体会到波特曼看到雷神和洛基生离死别时那种电灯泡的感觉',\n",
       " 'votes': '1866',\n",
       " 'star': '4',\n",
       " 'comment_time': '2013-11-10 05:17:36',\n",
       " 'watch_type': '看过',\n",
       " 'rank': 1,\n",
       " 'comment_id': 1,\n",
       " 'movie_url': 'https://movie.douban.com/subject/6560058/',\n",
       " 'entities': ['波特曼 PER', '雷神 PER', '洛基 PER']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_texts = []\n",
    "for comment in comments:\n",
    "    comment_texts.append(comment['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 用户画像（TODO）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mp_user_comment_num = {}\n",
    "for comment in comments:\n",
    "    if comment['user_url'] in mp_user_comment_num:\n",
    "        mp_user_comment_num[comment['user_url']] += 1\n",
    "    else:\n",
    "        mp_user_comment_num[comment['user_url']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133868, 1102111)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mp_user_comment_num), len(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333.477037191391\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "comment_texts_tfidf_svd, tfidf_vec_comment, svd_comment = build_tfidf_svd_matrix(comment_texts, 16)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../middle_data/svd_comment.sk.model']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(tfidf_vec_comment, '../middle_data/tfidf_vec_comment.sk.model')\n",
    "dump(svd_comment, '../middle_data/svd_comment.sk.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_comment_id_tfidf = {}\n",
    "for i in range(comment_texts_tfidf_svd.shape[0]):\n",
    "    mp_comment_id_tfidf[comments[i]['comment_id']] = comment_texts_tfidf_svd[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评论长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_len_V = np.zeros((len(comments), 1))\n",
    "for i, comment in enumerate(comments):\n",
    "    comment_len_V[i,0] = len(comment['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_comment_len = {}\n",
    "for i in range(comment_len_V.shape[0]):\n",
    "    mp_comment_len[comments[i]['comment_id']] = comment_len_V[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并电影和评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': {'score': '7.4',\n",
       "  'title': '\\n雷神2：黑暗世界 Thor: The Dark World\\n(2013)\\n',\n",
       "  'summary': '纽约大战后，雷神索尔（克里斯·海姆斯沃斯 Chris Hemsworth 饰）将弟弟洛基（汤姆·希德勒斯顿 Tom Hiddleston 饰）带回仙宫囚禁起来，此外帮助九大国度平定纷争，威名扶摇直上。虽然父王奥丁（安东尼·霍普金斯 Anthony Hopkins 饰）劝其及早即位，但索尔念念不忘地球的美丽女孩简·福斯特（娜塔丽·波特曼 Natalie Portman 饰）。与此同时，简在和黛西及其助手伊安调查某个区域时意外被神秘物质入侵，却也因此重逢索尔，并随其返回仙宫。令人意想不到的是，藏在简体内的物质来自远古的黑暗精灵玛勒基斯（克里斯托弗·埃克莱斯顿 Christopher Eccleston 饰）。在“天体汇聚”的时刻再次到来之际，玛勒基斯企图摧毁九大国度，缔造一个全然黑暗的宇宙。\\n                                        \\n                                    \\u3000\\u3000藏匿简的仙宫受到重创，而索尔和洛基这对冤家兄弟也不得不联手迎战...',\n",
       "  'directors': ['阿兰·泰勒'],\n",
       "  'writer': ['克里斯托弗·约斯特',\n",
       "   '克里斯托弗·马库斯',\n",
       "   '斯蒂芬·麦克菲利',\n",
       "   '唐·佩恩',\n",
       "   '罗伯特·罗达特',\n",
       "   '斯坦·李',\n",
       "   '拉里·利伯',\n",
       "   '杰克·科比',\n",
       "   '沃尔特·西蒙森'],\n",
       "  'actor': ['克里斯·海姆斯沃斯',\n",
       "   '娜塔莉·波特曼',\n",
       "   '汤姆·希德勒斯顿',\n",
       "   '安东尼·霍普金斯',\n",
       "   '克里斯托弗·埃克莱斯顿',\n",
       "   '杰米·亚历山大',\n",
       "   '扎克瑞·莱维',\n",
       "   '雷·史蒂文森',\n",
       "   '浅野忠信',\n",
       "   '伊德里斯·艾尔巴',\n",
       "   '蕾妮·罗素',\n",
       "   '阿德沃尔·阿吉纽依-艾格拜吉',\n",
       "   '凯特·戴琳斯',\n",
       "   '斯特兰·斯卡斯加德',\n",
       "   '艾丽丝·克里奇',\n",
       "   '克里夫·罗素',\n",
       "   '乔纳森·霍华德',\n",
       "   '克里斯·奥多德',\n",
       "   '妲露拉·莱莉',\n",
       "   '奥菲利亚·拉维邦德',\n",
       "   '本尼西奥·德尔·托罗',\n",
       "   '斯坦·李'],\n",
       "  'country': ' 美国',\n",
       "  'minutes': '112分钟',\n",
       "  'type': ['动作', '奇幻', '冒险'],\n",
       "  'releasedDate': ['2013-11-08(中国大陆/美国)'],\n",
       "  'recommended_urls': ['https://movie.douban.com/subject/1866471/',\n",
       "   'https://movie.douban.com/subject/1866471/',\n",
       "   'https://movie.douban.com/subject/3066739/',\n",
       "   'https://movie.douban.com/subject/3066739/',\n",
       "   'https://movie.douban.com/subject/6390823/',\n",
       "   'https://movie.douban.com/subject/6390823/',\n",
       "   'https://movie.douban.com/subject/10741834/',\n",
       "   'https://movie.douban.com/subject/10741834/',\n",
       "   'https://movie.douban.com/subject/1866475/',\n",
       "   'https://movie.douban.com/subject/1866475/',\n",
       "   'https://movie.douban.com/subject/1866473/',\n",
       "   'https://movie.douban.com/subject/1866473/',\n",
       "   'https://movie.douban.com/subject/10485647/',\n",
       "   'https://movie.douban.com/subject/10485647/',\n",
       "   'https://movie.douban.com/subject/3025375/',\n",
       "   'https://movie.douban.com/subject/3025375/',\n",
       "   'https://movie.douban.com/subject/7065154/',\n",
       "   'https://movie.douban.com/subject/7065154/',\n",
       "   'https://movie.douban.com/subject/6082518/',\n",
       "   'https://movie.douban.com/subject/6082518/'],\n",
       "  'collected_num': '49023',\n",
       "  'wish_num': '1173',\n",
       "  'movie_url': 'https://movie.douban.com/subject/6560058/',\n",
       "  'entities': ['纽约 LOC',\n",
       "   '雷神索尔 PER',\n",
       "   '克里斯·海姆斯沃斯 PER',\n",
       "   '洛基 PER',\n",
       "   '汤姆·希德勒斯顿 PER',\n",
       "   '奥丁 PER',\n",
       "   '安东尼·霍普金斯 PER']},\n",
       " 'right_comment': {'user_url': 'https://www.douban.com/people/questwoo/',\n",
       "  'comment_text': '我能体会到波特曼看到雷神和洛基生离死别时那种电灯泡的感觉',\n",
       "  'votes': '1866',\n",
       "  'star': '4',\n",
       "  'comment_time': '2013-11-10 05:17:36',\n",
       "  'watch_type': '看过',\n",
       "  'rank': 1,\n",
       "  'comment_id': 1,\n",
       "  'movie_url': 'https://movie.douban.com/subject/6560058/',\n",
       "  'entities': ['波特曼 PER', '雷神 PER', '洛基 PER']},\n",
       " 'wrong_comment': {'user_url': 'https://www.douban.com/people/zhoubin5371/',\n",
       "  'comment_text': 'Style drama, not such blonde as we could imagine',\n",
       "  'votes': '0',\n",
       "  'star': '3',\n",
       "  'comment_time': '2018-03-04 08:24:20',\n",
       "  'watch_type': '看过',\n",
       "  'rank': 369,\n",
       "  'comment_id': 165149,\n",
       "  'movie_url': 'https://movie.douban.com/subject/26386034/',\n",
       "  'entities': []}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不带实体重叠特征抽取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_substrs(str1, str2, min_len):\n",
    "    \"\"\"\n",
    "    在str1中寻找出现在str2的子串\n",
    "    \"\"\"\n",
    "    substr_list = []  # 保存两者相同的子串\n",
    "    s = 0  # 记录str1起始位置\n",
    "    e = 1  # 记录str1终止位置\n",
    "    match_num = 0  # 匹配个数\n",
    "    is_final = False  # 是否结束匹配过程：终止位置到达str1的最后一个位置\n",
    "    while not is_final:\n",
    "        cur_str = str1[s:e]\n",
    "        if cur_str in str2:\n",
    "            match_num += 1\n",
    "            if e == len(str1):\n",
    "                if len(cur_str) >= min_len:\n",
    "                    substr_list.append(str1[s:s + match_num])\n",
    "                is_final = True\n",
    "            else:\n",
    "                e += 1\n",
    "        else:\n",
    "            if match_num < min_len:\n",
    "                s += 1\n",
    "                if e != len(str1):\n",
    "                    e += 1\n",
    "            else:\n",
    "                substr_list.append(str1[s:s + match_num])\n",
    "                s = s + match_num\n",
    "                e = s + 1\n",
    "                match_num = 0\n",
    "    return substr_list\n",
    "\n",
    "def get_feature_movie_comment(movie, comment):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        movie:\n",
    "        comment:\n",
    "    Returns:\n",
    "        vector:\n",
    "        第一维：命中电影summary长度为2的数量累积加权\n",
    "        第二维：命中电影summary长度大于2的数量累积加权\n",
    "        第三维：命中导演数量\n",
    "        第四维：命中编剧数量\n",
    "        第五维：命中演员数量\n",
    "    \"\"\"\n",
    "    comment_text = re.sub('，|“|”|、|；|、|。|…|\\.|的|时候|个|·|）|（| ', '', comment['comment_text'])\n",
    "    len_comment = len(comment_text)\n",
    "    len_movie_summary = len(movie['summary'])\n",
    "    vector = np.zeros((5,))\n",
    "    if(len_comment == 0):\n",
    "        return vector\n",
    "    \n",
    "    substr_list = get_common_substrs(comment_text, movie['summary'], 2)\n",
    "    for i, sub_srt in enumerate(substr_list):\n",
    "        len_sub_str = len(sub_srt)\n",
    "        if(len_sub_str == 2):\n",
    "            vector[0] += 2\n",
    "        elif(len_sub_str > 2):\n",
    "            vector[1] += len_sub_str\n",
    "    for director in movie['directors']:\n",
    "        substr = get_common_substrs(director, comment_text, 2) \n",
    "        if(len(substr) > 0):\n",
    "            vector[2] += 1\n",
    "    \n",
    "    \n",
    "    for writer in movie['writer']:\n",
    "        substr = get_common_substrs(writer, comment_text, 2) \n",
    "        if(len(substr) > 0):\n",
    "            vector[3] += 1\n",
    "\n",
    "    for actor in movie['actor']:\n",
    "        substr = get_common_substrs(actor, comment_text, 2) \n",
    "        if(len(substr) > 0):\n",
    "            vector[4] += 1\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带实体重叠特征抽取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_movie_entity(movie, comment):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    vector = np.zeros((4, ))\n",
    "    movie_info_text = movie['title'] + movie['summary'] + ''.join(movie['directors']) + ''.join(movie['actor']) + ''.join(movie['writer'])\n",
    "    for item in comment['entities']:\n",
    "        entity, entity_type = item.split(' ')\n",
    "        if(entity in movie_info_text):\n",
    "            vector[{'PER':0, 'LOC':1, 'ORG':2}[entity_type]] += len(entity)\n",
    "    vector[3] = len(comment['entities'])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始特征拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_feature_len = list(mp_movie_url_vector.values())[0].shape[0]\n",
    "comment_feature_len = list(mp_comment_id_tfidf.values())[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(samples), movie_feature_len + 2 * comment_feature_len + 2))\n",
    "y = np.zeros((len(samples), ))\n",
    "for i, sample in enumerate(samples):\n",
    "    y[i] = random.randint(0, 1)\n",
    "    X[i][:movie_feature_len] = mp_movie_url_vector[sample['movie']['movie_url']]    \n",
    "    if(y[i] == 1):\n",
    "        X[i][movie_feature_len : movie_feature_len+comment_feature_len] = mp_comment_id_tfidf[sample['right_comment']['comment_id']]\n",
    "        X[i][movie_feature_len+comment_feature_len : -2] = mp_comment_id_tfidf[sample['wrong_comment']['comment_id']]\n",
    "        X[i][-2] = mp_comment_len[sample['right_comment']['comment_id']]\n",
    "        X[i][-1] = mp_comment_len[sample['wrong_comment']['comment_id']]\n",
    "    else:\n",
    "        X[i][movie_feature_len : movie_feature_len+comment_feature_len] = mp_comment_id_tfidf[sample['wrong_comment']['comment_id']]\n",
    "        X[i][movie_feature_len+comment_feature_len : -2] = mp_comment_id_tfidf[sample['right_comment']['comment_id']]   \n",
    "        X[i][-2] = mp_comment_len[sample['wrong_comment']['comment_id']]\n",
    "        X[i][-1] = mp_comment_len[sample['right_comment']['comment_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不带实体，电影 评论重叠信息特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.001462697982788086\n",
      "100000 22.28075861930847\n",
      "200000 41.32304406166077\n",
      "300000 60.56052017211914\n",
      "400000 79.5658507347107\n",
      "500000 99.0408239364624\n",
      "600000 116.77722835540771\n",
      "700000 136.76764059066772\n",
      "800000 154.00202441215515\n",
      "900000 174.89814472198486\n",
      "1000000 193.63973832130432\n",
      "1100000 209.95308136940002\n",
      "1200000 228.68139696121216\n",
      "1300000 245.39527702331543\n",
      "1400000 261.04314708709717\n",
      "1500000 277.9171690940857\n",
      "1600000 298.94186186790466\n",
      "1700000 315.6571078300476\n",
      "1800000 332.50941705703735\n",
      "1900000 348.54197096824646\n",
      "2000000 362.30759596824646\n",
      "2100000 378.5216863155365\n",
      "2200000 395.3744332790375\n",
      "2300000 409.1595256328583\n",
      "2400000 423.6898171901703\n",
      "2500000 439.22526502609253\n",
      "2600000 456.29476618766785\n",
      "2700000 474.1492028236389\n",
      "2800000 488.7256762981415\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cnt = 0\n",
    "\n",
    "hit_feature_number = 5\n",
    "X_hit_features = np.zeros((len(samples), hit_feature_number * 2))\n",
    "for i, sample in enumerate(samples):\n",
    "    v_right = get_feature_movie_comment(sample['movie'], sample['right_comment'])\n",
    "    v_wrong = get_feature_movie_comment(sample['movie'], sample['wrong_comment'])\n",
    "    if(y[i] == 1):\n",
    "        X_hit_features[i][:hit_feature_number] = v_right\n",
    "        X_hit_features[i][hit_feature_number:] = v_wrong\n",
    "    else:\n",
    "        X_hit_features[i][:hit_feature_number] = v_wrong\n",
    "        X_hit_features[i][hit_feature_number:] = v_right\n",
    "    \n",
    "    if(cnt % 100000 == 0):\n",
    "        print(cnt, time.time() - start)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实体特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0013370513916015625\n",
      "100000 1.070570468902588\n",
      "200000 2.006481409072876\n",
      "300000 2.9521169662475586\n",
      "400000 3.9089112281799316\n",
      "500000 4.853625774383545\n",
      "600000 5.878629207611084\n",
      "700000 7.022550106048584\n",
      "800000 8.112439155578613\n",
      "900000 9.233209371566772\n",
      "1000000 10.368393898010254\n",
      "1100000 11.515652894973755\n",
      "1200000 12.627682209014893\n",
      "1300000 13.656734466552734\n",
      "1400000 14.59129524230957\n",
      "1500000 15.540847301483154\n",
      "1600000 16.619782209396362\n",
      "1700000 17.604134798049927\n",
      "1800000 18.55076837539673\n",
      "1900000 19.530085563659668\n",
      "2000000 20.47172713279724\n",
      "2100000 21.444985389709473\n",
      "2200000 22.397820234298706\n",
      "2300000 23.478790998458862\n",
      "2400000 24.374224424362183\n",
      "2500000 25.297502517700195\n",
      "2600000 26.40814471244812\n",
      "2700000 27.474499940872192\n",
      "2800000 28.60411763191223\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cnt = 0\n",
    "\n",
    "entity_feature_number = 4\n",
    "X_entity_feature = np.zeros((len(samples), entity_feature_number * 2))\n",
    "for i, sample in enumerate(samples):\n",
    "    v_right = get_feature_movie_entity(sample['movie'], sample['right_comment'])\n",
    "    v_wrong = get_feature_movie_entity(sample['movie'], sample['wrong_comment'])\n",
    "    if(y[i] == 1):\n",
    "        X_entity_feature[i][:entity_feature_number] = v_right\n",
    "        X_entity_feature[i][entity_feature_number:] = v_wrong\n",
    "    else:\n",
    "        X_entity_feature[i][:entity_feature_number] = v_wrong\n",
    "        X_entity_feature[i][entity_feature_number:] = v_right\n",
    "    \n",
    "    if(cnt % 100000 == 0):\n",
    "        print(cnt, time.time() - start)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_all = np.concatenate((X, X_hit_features), axis=1)\n",
    "X_all = np.concatenate((X, X_hit_features, X_entity_feature), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2842112, 133), (2842112,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2842112, 151)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluation(score, ground_truth, threshold):\n",
    "    \"\"\"\n",
    "    print the evaluation results for binary classification\n",
    "    Args:\n",
    "        score: the predict results\n",
    "        ground_truth: the truth label\n",
    "        threshold: when score is lager than threshold will be considered as a positive sample\n",
    "    \"\"\"\n",
    "    print('准确率：%f' % accuracy_score(ground_truth, score>0.5))\n",
    "    print('AUC: %f' % roc_auc_score(ground_truth, score))\n",
    "    print('F1: %f' % f1_score(ground_truth, score > threshold, average='macro'))\n",
    "    print('混淆矩阵：')\n",
    "    df_confusion_matrix = pd.DataFrame(confusion_matrix(ground_truth, score > threshold))\n",
    "    display(HTML(df_confusion_matrix.to_html()))\n",
    "    \n",
    "    print('准召报告')\n",
    "    df_precision_recall_fscore = pd.DataFrame(precision_recall_fscore_support(ground_truth, score > threshold), index = ['precision', 'recall', 'f1', 'number'])\n",
    "    display(HTML(df_precision_recall_fscore.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1988761, 131), (852327, 131), (1988761,), (852327,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 1988761\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = X_all[:train_len], X_all[train_len:], y[:train_len], y[train_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_score = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：0.568420\n",
      "AUC: 0.589034\n",
      "F1: 0.568404\n",
      "混淆矩阵：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244837</td>\n",
       "      <td>181964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185883</td>\n",
       "      <td>239643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准召报告\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.568437</td>\n",
       "      <td>0.568404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.573656</td>\n",
       "      <td>0.563169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.571034</td>\n",
       "      <td>0.565774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>426801.000000</td>\n",
       "      <td>425526.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation(test_score, y_test, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104, 102, 112, 130, 103, 109, 122, 107, 115, 129, 121, 101, 100,\n",
       "        110,  82,  69,  81, 108,  85,  60,  70,  84,  62,  17,  67,  90,\n",
       "         53,  80,  63,  71, 111,  91,  47,   2,  54,  76,  83,  42,  56,\n",
       "         48,  20,  88,  72,   3,  86,  44,  89,  51,   0, 127,  24,   9,\n",
       "         73,  75,   5,  26,  92,  21,  96,  10,  14,  97,   6,  45,  18,\n",
       "         22,  32,  34,  12,  33,  30,  25,   1,  31,  37,  77,  29,   8,\n",
       "          4,   7,  41,  19,  39,  15,  13,  87,  27,  64,  50,  36,  23,\n",
       "         11,  28,  16,  46,  74,  68,  94,  98,  61,  95,  57,  49,  65,\n",
       "         43,  38,  93,  35,  78,  79,  55,  58,  40,  59,  52,  66, 124,\n",
       "        126, 116, 117, 113, 105,  99, 125, 123, 106, 119, 114, 128, 118,\n",
       "        120]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds\n",
      "[5000]\ttraining's auc: 0.904294\n",
      "[10000]\ttraining's auc: 0.923158\n",
      "[15000]\ttraining's auc: 0.937499\n",
      "[20000]\ttraining's auc: 0.949044\n",
      "[25000]\ttraining's auc: 0.958261\n",
      "[30000]\ttraining's auc: 0.965698\n",
      "[35000]\ttraining's auc: 0.97175\n",
      "[40000]\ttraining's auc: 0.97656\n",
      "[45000]\ttraining's auc: 0.980574\n",
      "[50000]\ttraining's auc: 0.983851\n",
      "[55000]\ttraining's auc: 0.986574\n",
      "[60000]\ttraining's auc: 0.988869\n",
      "[65000]\ttraining's auc: 0.990749\n",
      "[70000]\ttraining's auc: 0.992308\n",
      "[75000]\ttraining's auc: 0.993601\n",
      "[80000]\ttraining's auc: 0.994702\n",
      "[85000]\ttraining's auc: 0.995591\n",
      "[90000]\ttraining's auc: 0.996348\n",
      "[95000]\ttraining's auc: 0.996975\n",
      "[100000]\ttraining's auc: 0.997498\n",
      "[105000]\ttraining's auc: 0.997928\n",
      "[110000]\ttraining's auc: 0.998291\n",
      "[115000]\ttraining's auc: 0.998585\n",
      "[120000]\ttraining's auc: 0.998833\n",
      "[125000]\ttraining's auc: 0.999042\n",
      "[130000]\ttraining's auc: 0.999212\n",
      "[135000]\ttraining's auc: 0.999351\n",
      "[140000]\ttraining's auc: 0.999467\n",
      "[145000]\ttraining's auc: 0.999564\n",
      "[150000]\ttraining's auc: 0.999644\n",
      "[155000]\ttraining's auc: 0.999708\n",
      "[160000]\ttraining's auc: 0.999761\n",
      "[165000]\ttraining's auc: 0.999805\n",
      "[170000]\ttraining's auc: 0.999841\n",
      "[175000]\ttraining's auc: 0.99987\n",
      "[180000]\ttraining's auc: 0.999895\n",
      "[185000]\ttraining's auc: 0.999915\n",
      "[190000]\ttraining's auc: 0.999931\n",
      "[195000]\ttraining's auc: 0.999944\n",
      "[200000]\ttraining's auc: 0.999954\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200000]\ttraining's auc: 0.999954\n",
      "38708.99653959274\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'is_unbalance': True,\n",
    "    'min_data_in_leaf': 160,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "start = time.time()\n",
    "trn_data = lgb.Dataset(X_train_all, label=y_train_all)\n",
    "lgb_clf = lgb.train(param, trn_data, 200000, valid_sets = [trn_data], verbose_eval=5000, early_stopping_rounds=4000)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_lgb = lgb_clf.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：0.985670\n",
      "AUC: 0.998740\n",
      "F1: 0.985670\n",
      "混淆矩阵：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419773</td>\n",
       "      <td>6042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6176</td>\n",
       "      <td>420643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准召报告\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.985501</td>\n",
       "      <td>0.985840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.985811</td>\n",
       "      <td>0.985530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.985656</td>\n",
       "      <td>0.985685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>425815.000000</td>\n",
       "      <td>426819.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation(test_score_lgb, y_test_all, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f4b743ab5f8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf.save_model('../middle_data/lgb_clf_with_entity.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        2.30000000e+01,  4.90000000e+01,  3.40000000e+02,  9.47419621e-02,\n",
       "        2.77242859e-02, -3.44640431e-03, -2.17476860e-02, -3.65413345e-03,\n",
       "        2.97852039e-03, -1.26442155e-02, -5.38940794e-03,  8.06771794e-03,\n",
       "       -3.12733724e-02, -8.59134428e-03,  1.58928494e-02,  1.02797762e-02,\n",
       "       -2.87237182e-03, -2.37320565e-02,  1.85256534e-02,  3.62213841e-02,\n",
       "        3.31014362e-02, -1.38782636e-02, -4.80535918e-02, -2.18006242e-02,\n",
       "       -3.61298109e-02,  5.37809595e-02,  2.05092991e-02,  6.06675854e-02,\n",
       "        1.63341111e-02, -4.40793647e-03, -2.77769803e-02,  3.50979916e-02,\n",
       "        3.00351314e-02,  1.97611926e-02, -1.84346729e-02, -3.77599084e-02,\n",
       "        4.80871609e-03,  1.27559904e-02,  4.74320180e-02, -5.91140913e-02,\n",
       "       -4.25895222e-02,  4.23120389e-02,  4.72894947e-03, -1.64897231e-02,\n",
       "        1.03327549e-01, -3.91940994e-03, -9.59686461e-03, -7.94608915e-03,\n",
       "        1.27629299e-02, -1.84235735e-03, -4.90388153e-02, -2.40224349e-03,\n",
       "       -5.51558311e-02, -5.64764786e-03,  5.16851719e-02, -3.36191654e-03,\n",
       "       -1.04388705e-02,  3.87095810e-02,  1.62156301e-03, -2.53273944e-02,\n",
       "       -1.92737959e-02,  4.41284340e-03,  4.80687000e-02,  2.89584269e-02,\n",
       "        1.19092583e-03, -2.26677969e-02,  1.82252425e-02,  4.82332501e-02,\n",
       "       -6.07700887e-03,  2.08336728e-02, -6.79454777e-03, -8.24708353e-02,\n",
       "        1.47644513e-01,  1.89094181e-01, -5.51871730e-02, -3.36956192e-02,\n",
       "        9.57698950e-04, -3.86106581e-02,  1.14131326e-02, -3.27768184e-02,\n",
       "        8.98803222e-06, -8.87460767e-03, -1.84046598e-02,  8.43429018e-02,\n",
       "       -1.95170841e-02, -9.44051931e-04, -4.13092766e-02, -1.20102952e-02,\n",
       "       -1.06922372e-02,  5.23917606e-03,  4.77830483e-02, -4.69820453e-02,\n",
       "        7.83877848e-03, -1.20484694e-02, -5.97717114e-03, -8.53456310e-03,\n",
       "       -2.03138640e-03,  1.13487738e-03, -8.26627335e-03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
