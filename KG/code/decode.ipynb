{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "with open('../data/comments_clean.json', 'r') as f:\n",
    "    for line in f:\n",
    "        comments.append(json.loads(line.strip()))\n",
    "movies = []\n",
    "with open('../data/movies_clean.json', 'r') as f:\n",
    "    for line in f:\n",
    "        movies.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_movie_comments = {}\n",
    "for comment in comments:\n",
    "    comment_list = mp_movie_comments.get(comment['movie_url'], 0)\n",
    "    if(comment_list is 0):\n",
    "        mp_movie_comments[comment['movie_url']] = [comment,]\n",
    "    else:\n",
    "        mp_movie_comments[comment['movie_url']].append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 8.059362888336182\n",
      "2000 13.399475336074829\n",
      "18.444490909576416\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "sample_movie_num = 2\n",
    "sample_comment_num = 32\n",
    "use_movie_comment_num = 16\n",
    "cnt = 1\n",
    "start = time.time()\n",
    "y = []\n",
    "\n",
    "for movie in movies:\n",
    "    movie_url = movie['movie_url']\n",
    "    if(mp_movie_comments.get(movie_url, 0) is 0):\n",
    "        continue\n",
    "    other_movies = random.sample(movies, sample_movie_num)\n",
    "    other_comments = []\n",
    "    for other_movie in other_movies:\n",
    "        other_url = other_movie['movie_url']\n",
    "        if other_url == movie_url:\n",
    "            continue\n",
    "        if(mp_movie_comments.get(other_url, 0) is 0):\n",
    "            continue\n",
    "        other_comments.extend(mp_movie_comments[other_url][-sample_comment_num:])\n",
    "    for comment in mp_movie_comments[movie_url][:use_movie_comment_num]:\n",
    "        for other_comment in other_comments:\n",
    "            target = random.randint(0, 1)\n",
    "            y.append(target)\n",
    "            a_sample = {}\n",
    "            a_sample['movie'] = movie\n",
    "            if target == 1:\n",
    "                a_sample['comment_a'] = comment\n",
    "                a_sample['comment_b'] = other_comment\n",
    "            else:\n",
    "                a_sample['comment_a'] = other_comment\n",
    "                a_sample['comment_b'] = comment\n",
    "\n",
    "            samples.append(a_sample)\n",
    "    cnt += 1\n",
    "    if(cnt % 1000 == 0):\n",
    "        print(cnt, time.time() - start)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': {'score': '7.4',\n",
       "  'title': '\\n雷神2：黑暗世界 Thor: The Dark World\\n(2013)\\n',\n",
       "  'summary': '纽约大战后，雷神索尔（克里斯·海姆斯沃斯 Chris Hemsworth 饰）将弟弟洛基（汤姆·希德勒斯顿 Tom Hiddleston 饰）带回仙宫囚禁起来，此外帮助九大国度平定纷争，威名扶摇直上。虽然父王奥丁（安东尼·霍普金斯 Anthony Hopkins 饰）劝其及早即位，但索尔念念不忘地球的美丽女孩简·福斯特（娜塔丽·波特曼 Natalie Portman 饰）。与此同时，简在和黛西及其助手伊安调查某个区域时意外被神秘物质入侵，却也因此重逢索尔，并随其返回仙宫。令人意想不到的是，藏在简体内的物质来自远古的黑暗精灵玛勒基斯（克里斯托弗·埃克莱斯顿 Christopher Eccleston 饰）。在“天体汇聚”的时刻再次到来之际，玛勒基斯企图摧毁九大国度，缔造一个全然黑暗的宇宙。\\n                                        \\n                                    \\u3000\\u3000藏匿简的仙宫受到重创，而索尔和洛基这对冤家兄弟也不得不联手迎战...',\n",
       "  'directors': ['阿兰·泰勒'],\n",
       "  'writer': ['克里斯托弗·约斯特',\n",
       "   '克里斯托弗·马库斯',\n",
       "   '斯蒂芬·麦克菲利',\n",
       "   '唐·佩恩',\n",
       "   '罗伯特·罗达特',\n",
       "   '斯坦·李',\n",
       "   '拉里·利伯',\n",
       "   '杰克·科比',\n",
       "   '沃尔特·西蒙森'],\n",
       "  'actor': ['克里斯·海姆斯沃斯',\n",
       "   '娜塔莉·波特曼',\n",
       "   '汤姆·希德勒斯顿',\n",
       "   '安东尼·霍普金斯',\n",
       "   '克里斯托弗·埃克莱斯顿',\n",
       "   '杰米·亚历山大',\n",
       "   '扎克瑞·莱维',\n",
       "   '雷·史蒂文森',\n",
       "   '浅野忠信',\n",
       "   '伊德里斯·艾尔巴',\n",
       "   '蕾妮·罗素',\n",
       "   '阿德沃尔·阿吉纽依-艾格拜吉',\n",
       "   '凯特·戴琳斯',\n",
       "   '斯特兰·斯卡斯加德',\n",
       "   '艾丽丝·克里奇',\n",
       "   '克里夫·罗素',\n",
       "   '乔纳森·霍华德',\n",
       "   '克里斯·奥多德',\n",
       "   '妲露拉·莱莉',\n",
       "   '奥菲利亚·拉维邦德',\n",
       "   '本尼西奥·德尔·托罗',\n",
       "   '斯坦·李'],\n",
       "  'country': ' 美国',\n",
       "  'minutes': '112分钟',\n",
       "  'type': ['动作', '奇幻', '冒险'],\n",
       "  'releasedDate': ['2013-11-08(中国大陆/美国)'],\n",
       "  'recommended_urls': ['https://movie.douban.com/subject/1866471/',\n",
       "   'https://movie.douban.com/subject/1866471/',\n",
       "   'https://movie.douban.com/subject/3066739/',\n",
       "   'https://movie.douban.com/subject/3066739/',\n",
       "   'https://movie.douban.com/subject/6390823/',\n",
       "   'https://movie.douban.com/subject/6390823/',\n",
       "   'https://movie.douban.com/subject/10741834/',\n",
       "   'https://movie.douban.com/subject/10741834/',\n",
       "   'https://movie.douban.com/subject/1866475/',\n",
       "   'https://movie.douban.com/subject/1866475/',\n",
       "   'https://movie.douban.com/subject/1866473/',\n",
       "   'https://movie.douban.com/subject/1866473/',\n",
       "   'https://movie.douban.com/subject/10485647/',\n",
       "   'https://movie.douban.com/subject/10485647/',\n",
       "   'https://movie.douban.com/subject/3025375/',\n",
       "   'https://movie.douban.com/subject/3025375/',\n",
       "   'https://movie.douban.com/subject/7065154/',\n",
       "   'https://movie.douban.com/subject/7065154/',\n",
       "   'https://movie.douban.com/subject/6082518/',\n",
       "   'https://movie.douban.com/subject/6082518/'],\n",
       "  'collected_num': '49023',\n",
       "  'wish_num': '1173',\n",
       "  'movie_url': 'https://movie.douban.com/subject/6560058/'},\n",
       " 'comment_a': {'user_url': 'https://www.douban.com/people/yx2/',\n",
       "  'comment_text': '配乐画质剧情都很棒，不必每部动画都要挖掘神马人生意义，开心就好。比第一部酷多了！',\n",
       "  'votes': '0',\n",
       "  'star': '4',\n",
       "  'comment_time': '2011-08-29 14:55:56',\n",
       "  'watch_type': '看过',\n",
       "  'rank': 369,\n",
       "  'comment_id': 229949,\n",
       "  'movie_url': 'https://movie.douban.com/subject/3036478/'},\n",
       " 'comment_b': {'user_url': 'https://www.douban.com/people/questwoo/',\n",
       "  'comment_text': '我能体会到波特曼看到雷神和洛基生离死别时那种电灯泡的感觉',\n",
       "  'votes': '1866',\n",
       "  'star': '4',\n",
       "  'comment_time': '2013-11-10 05:17:36',\n",
       "  'watch_type': '看过',\n",
       "  'rank': 1,\n",
       "  'comment_id': 1,\n",
       "  'movie_url': 'https://movie.douban.com/subject/6560058/'}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "'''\n",
    "Created on Dec 17, 2019\n",
    "\n",
    "@author: Yongrui Huang\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class CommentCompare(object):\n",
    "    '''\n",
    "    classdocs\n",
    "    \n",
    "   A sample:\n",
    "    {\n",
    "    'movie': {\n",
    "              'title': '\\n雷神2：黑暗世界 Thor: The Dark World\\n(2013)\\n',\n",
    "              'summary': '纽约大战后，雷神索尔（克里斯·海姆斯沃斯 Chris Hemsworth 饰）将弟弟洛基（汤姆·希德勒斯顿 Tom Hiddleston 饰）带回仙宫囚禁起来，此外帮助九大国度平定纷争，威名扶摇直上。虽然父王奥丁（安东尼·霍普金斯 Anthony Hopkins 饰）劝其及早即位，但索尔念念不忘地球的美丽女孩简·福斯特（娜塔丽·波特曼 Natalie Portman 饰）。与此同时，简在和黛西及其助手伊安调查某个区域时意外被神秘物质入侵，却也因此重逢索尔，并随其返回仙宫。令人意想不到的是，藏在简体内的物质来自远古的黑暗精灵玛勒基斯（克里斯托弗·埃克莱斯顿 Christopher Eccleston 饰）。在“天体汇聚”的时刻再次到来之际，玛勒基斯企图摧毁九大国度，缔造一个全然黑暗的宇宙。\\n                                        \\n                                    \\u3000\\u3000藏匿简的仙宫受到重创，而索尔和洛基这对冤家兄弟也不得不联手迎战...',\n",
    "              'directors': ['阿兰·泰勒'],\n",
    "              'writer': ['克里斯托弗·约斯特', ...],\n",
    "              'actor': ['克里斯·海姆斯沃斯',...],\n",
    "              'type': ['动作', '奇幻', ...],\n",
    "              'movie_url': 'https://movie.douban.com/subject/6560058/' \n",
    "              },\n",
    "     'comment_a': {\n",
    "            'user_url': 'https://www.douban.com/people/questwoo/',\n",
    "            'comment_text': '我能体会到波特曼看到雷神和洛基生离死别时那种电灯泡的感觉',\n",
    "            'comment_id': 1,\n",
    "            },\n",
    "     'comment_b': {\n",
    "            'user_url': 'https://www.douban.com/people/yangchen1102/',\n",
    "            'comment_text': '奈特莉还真够平',\n",
    "            'comment_id': 250749,\n",
    "            }\n",
    "    }\n",
    "    \n",
    "    y_i : 1 indicate comment_a is better than comment_b for movies, 0 otherwise.\n",
    "    '''\n",
    "    \n",
    "    tfidf_vec_movie = None\n",
    "    svd_movie = None\n",
    "    tfidf_vec_comment = None\n",
    "    svd_comment = None\n",
    "    movie_feature_name = None\n",
    "    lgb_clf = None\n",
    "    \n",
    "    stop_words = set()\n",
    "    cnt_movie_num = 0\n",
    "    def __init__(self, params):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.load_stopwords()\n",
    "        self.tfidf_vec_movie = params['tfidf_vec_movie']\n",
    "        self.svd_movie = params['svd_movie']\n",
    "        self.tfidf_vec_comment = params['tfidf_vec_comment']\n",
    "        self.svd_comment = params['svd_comment']\n",
    "        self.movie_feature_name = params['movie_feature_name']\n",
    "        self.lgb_clf = params['lgb_clf']\n",
    "\n",
    "        \n",
    "    def predict(self, samples):\n",
    "        \n",
    "        movie_texts = []\n",
    "        movies = []\n",
    "        for sample in samples:\n",
    "            movie = sample['movie']\n",
    "            movies.append(movie)\n",
    "            movie_texts.append(self.clean_text(movie['title'] + movie['summary']))\n",
    "        df_movies = pd.DataFrame(np.zeros((len(samples), len(self.movie_feature_name))), columns = self.movie_feature_name)\n",
    "        self.cnt_movie_num = 0\n",
    "        def set_features(x):\n",
    "            movie = movies[self.cnt_movie_num]\n",
    "            self.cnt_movie_num += 1\n",
    "            x[movie['type']] = 1\n",
    "            x['len_directors'] = len(movie['directors'])\n",
    "            x['len_writer'] = len(movie['writer'])    \n",
    "            x['len_actor'] = len(movie['actor'])    \n",
    "            x['len_title'] = len(self.clean_text(movie['title']))\n",
    "            x['len_summary'] = len(self.clean_text(movie['summary']))\n",
    "        _ = df_movies.apply(set_features, axis = 1)\n",
    "\n",
    "        movie_texts_tfidf_svd = self.predict_tfidf_svd_matrix(movie_texts, self.tfidf_vec_movie, self.svd_movie)\n",
    "        tf_idf_movie_columns_names = ['td_idf_movie_%d' % i for i in range(movie_texts_tfidf_svd.shape[1])]\n",
    "        #1\n",
    "        df_tf_idf_movie_svd = pd.DataFrame(movie_texts_tfidf_svd, columns = tf_idf_movie_columns_names)\n",
    "        df_movies_with_tfidf = pd.concat([df_movies, df_tf_idf_movie_svd], axis=1)\n",
    "        \n",
    "        comments_text_a = []\n",
    "        comments_text_b = []\n",
    "        for sample in samples:\n",
    "            comments_text_a.append(sample['comment_a']['comment_text'])\n",
    "            comments_text_b.append(sample['comment_b']['comment_text'])\n",
    "        \n",
    "        #2\n",
    "        comment_texts_a_tfidf_svd = self.predict_tfidf_svd_matrix(comments_text_a, self.tfidf_vec_comment, self.svd_comment)\n",
    "        #3\n",
    "        comment_texts_b_tfidf_svd = self.predict_tfidf_svd_matrix(comments_text_b, self.tfidf_vec_comment, self.svd_comment)\n",
    "        \n",
    "        hit_feature_number = 5\n",
    "        #4\n",
    "        X_hit_features = np.zeros((len(samples), hit_feature_number * 2))\n",
    "\n",
    "        for i, sample in enumerate(samples):            \n",
    "            X_hit_features[i][:hit_feature_number] = self.get_feature_movie_comment(sample['movie'], sample['comment_a'])\n",
    "            X_hit_features[i][hit_feature_number:] = self.get_feature_movie_comment(sample['movie'], sample['comment_b'])\n",
    "        \n",
    "        X_all = np.concatenate((df_movies_with_tfidf.values, comment_texts_a_tfidf_svd, \\\n",
    "                                comment_texts_b_tfidf_svd, X_hit_features), axis = 1)\n",
    "        \n",
    "        return self.lgb_clf.predict(X_all), X_all\n",
    "    \n",
    "    \n",
    "    def get_common_substrs(self, str1, str2, min_len):\n",
    "        \"\"\"\n",
    "                        在str1中寻找出现在str2的子串\n",
    "        \"\"\"\n",
    "        substr_list = []  # 保存两者相同的子串\n",
    "        s = 0  # 记录str1起始位置\n",
    "        e = 1  # 记录str1终止位置\n",
    "        match_num = 0  # 匹配个数\n",
    "        is_final = False  # 是否结束匹配过程：终止位置到达str1的最后一个位置\n",
    "        while not is_final:\n",
    "            cur_str = str1[s:e]\n",
    "            if cur_str in str2:\n",
    "                match_num += 1\n",
    "                if e == len(str1):\n",
    "                    if len(cur_str) >= min_len:\n",
    "                        substr_list.append(str1[s:s + match_num])\n",
    "                    is_final = True\n",
    "                else:\n",
    "                    e += 1\n",
    "            else:\n",
    "                if match_num < min_len:\n",
    "                    s += 1\n",
    "                    if e != len(str1):\n",
    "                        e += 1\n",
    "                else:\n",
    "                    substr_list.append(str1[s:s + match_num])\n",
    "                    s = s + match_num\n",
    "                    e = s + 1\n",
    "                    match_num = 0\n",
    "        return substr_list\n",
    "    \n",
    "    \n",
    "    def get_feature_movie_comment(self, movie, comment):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            movie:\n",
    "            comment:\n",
    "        Returns:\n",
    "            vector:\n",
    "                                            第一维：命中电影summary长度为2的数量累积加权\n",
    "                                            第二维：命中电影summary长度大于2的数量累积加权\n",
    "                                            第三维：命中导演数量\n",
    "                                            第四维：命中编剧数量\n",
    "                                            第五维：命中演员数量\n",
    "        \"\"\"\n",
    "        comment_text = re.sub('，|“|”|、|；|、|。|…|\\.|的|时候|个|·|）|（| ', '', comment['comment_text'])\n",
    "        len_comment = len(comment_text)\n",
    "        len_movie_summary = len(movie['summary'])\n",
    "        vector = np.zeros((5,))\n",
    "        if(len_comment == 0):\n",
    "            return vector\n",
    "        \n",
    "        substr_list = self.get_common_substrs(comment_text, movie['summary'], 2)\n",
    "        for i, sub_srt in enumerate(substr_list):\n",
    "            len_sub_str = len(sub_srt)\n",
    "            if(len_sub_str == 2):\n",
    "                vector[0] += 2\n",
    "            elif(len_sub_str > 2):\n",
    "                vector[1] += len_sub_str\n",
    "        for director in movie['directors']:\n",
    "            substr = self.get_common_substrs(director, comment_text, 2) \n",
    "            if(len(substr) > 0):\n",
    "                vector[2] += 1\n",
    "        \n",
    "        \n",
    "        for writer in movie['writer']:\n",
    "            substr = self.get_common_substrs(writer, comment_text, 2) \n",
    "            if(len(substr) > 0):\n",
    "                vector[3] += 1\n",
    "    \n",
    "        for actor in movie['actor']:\n",
    "            substr = self.get_common_substrs(actor, comment_text, 2) \n",
    "            if(len(substr) > 0):\n",
    "                vector[4] += 1\n",
    "        \n",
    "        return vector\n",
    "    \n",
    "    \n",
    "    def predict_tfidf_svd_matrix(self, texts, tfidf_vec, svd):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        corpus = []\n",
    "        for text in texts:\n",
    "            words = self.word_segment(str(text))\n",
    "            use_words = []\n",
    "            for word in words:\n",
    "                if word in self.stop_words:\n",
    "                    continue\n",
    "                else:\n",
    "                    use_words.append(word)\n",
    "            corpus.append(' '.join(use_words))\n",
    "            \n",
    "        tfidf_matrix = tfidf_vec.transform(corpus)\n",
    "        tf_idf_svd = svd.transform(tfidf_matrix)\n",
    "        \n",
    "        return tf_idf_svd\n",
    "\n",
    "\n",
    "    def word_segment(self, sentence):\n",
    "        words = jieba.cut(sentence)\n",
    "        return ','.join(words).split(',')\n",
    "    \n",
    "    def load_stopwords(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        with open('../middle_data/stopwords.txt', 'r', encoding='UTF-8') as f:\n",
    "            for line in f.readlines():\n",
    "                self.stop_words.add(line.strip())\n",
    "        \n",
    "    def remove_stopwords(self, word_lists):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for word in word_lists:\n",
    "            if word not in self.stop_words:\n",
    "                res.append(word)\n",
    "        return ' '.join(res)\n",
    "     \n",
    "    def clean_text(self, string):\n",
    "        return string.replace(' ', '').replace('\\n', '').replace('\\u3000', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import lightgbm as lgb\n",
    "movie_features = load('../middle_data/movie_features.sk.var')\n",
    "tfidf_vec_movie = load('../middle_data/tfidf_vec_movie.sk.model')\n",
    "svd_movie = load('../middle_data/svd_movie.sk.model')\n",
    "tfidf_vec_comment = load('../middle_data/tfidf_vec_comment.sk.model')\n",
    "svd_comment = load('../middle_data/svd_comment.sk.model')\n",
    "lgb_clf = lgb.Booster(model_file='../middle_data/lgb_clf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfidf_vec_movie': tfidf_vec_movie,\n",
    "    'svd_movie': svd_movie,\n",
    "    'tfidf_vec_comment':tfidf_vec_comment,\n",
    "    'svd_comment':svd_comment,\n",
    "    'movie_feature_name':movie_features,  \n",
    "    'lgb_clf':lgb_clf,\n",
    "}\n",
    "decoder = CommentCompare(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 213000\n",
    "pre_score, X = decoder.predict(samples[start_idx:start_idx+1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluation(score, ground_truth, threshold):\n",
    "    \"\"\"\n",
    "    print the evaluation results for binary classification\n",
    "    Args:\n",
    "        score: the predict results\n",
    "        ground_truth: the truth label\n",
    "        threshold: when score is lager than threshold will be considered as a positive sample\n",
    "    \"\"\"\n",
    "    print('准确率：%f' % accuracy_score(ground_truth, score>0.5))\n",
    "    print('AUC: %f' % roc_auc_score(ground_truth, score))\n",
    "    print('F1: %f' % f1_score(ground_truth, score > threshold, average='macro'))\n",
    "    print('混淆矩阵：')\n",
    "    df_confusion_matrix = pd.DataFrame(confusion_matrix(ground_truth, score > threshold))\n",
    "    display(HTML(df_confusion_matrix.to_html()))\n",
    "    \n",
    "    print('准召报告')\n",
    "    df_precision_recall_fscore = pd.DataFrame(precision_recall_fscore_support(ground_truth, score > threshold), index = ['precision', 'recall', 'f1', 'number'])\n",
    "    display(HTML(df_precision_recall_fscore.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：0.913000\n",
      "AUC: 0.968095\n",
      "F1: 0.912985\n",
      "混淆矩阵：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准召报告\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.920245</td>\n",
       "      <td>0.906067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.922311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.911854</td>\n",
       "      <td>0.914116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>502.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation(pre_score, y[start_idx:start_idx+1000], .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_sample = {\n",
    "    'movie':{'actor': ['米哈乌·多科罗曼斯基', '米洛斯·科佩基', '鲁道夫·霍辛斯基', '纳达·康瓦林科夫'],\n",
    "             'type': ['喜剧', '犯罪'], \n",
    "             'summary': '美国最伟大的侦探尼克·卡特又有了新难题！一位布拉格贵妇家发生一起离奇的失踪案，卡特火速启程，不料却发现案件比预想还要脱轨。多年前沉入沼泽的死对头为何重现江湖？种满毒草的温室内又究竟隐藏了怎样的秘密？卡特无所不用其极，搬出化学实验台，戴上拳拳防身帽，一边收拾助手的烂摊子，一边周旋于自己的老对头。捷克经典馆藏全新修复，史云梅耶亲自上阵设计动画，为影片带来夸张又癫狂的视觉效果。事不宜迟……先坐下来喝杯当地风味纯正的皮尔森酒，咬上几口香肠，再看卡特和他的助手如何擒拿罪犯。', \n",
    "             'title': '\\n阿黛尔还没吃晚餐 Adéla jeste nevecerela\\n(1978)\\n', \n",
    "             'directors': ['奥德里奇·利普斯基'], \n",
    "             'writer': ['伊里·布尔德奇卡']},\n",
    "    'comment_a':{\n",
    "         'comment_text':\"这也太搞笑了吧，尼克随随便便就破案了\",\n",
    "    },\n",
    "    'comment_b':{\n",
    "        'comment_text':'定格+真人，史上装备最全的侦探智斗恶魔科学家，笑料足，脑洞大，充满东欧式讽谑喜剧味；各种新奇设备的加持，为简单欢乐的破案提升“技术”参数。身披黑袍屋顶行走，如佐罗附身，身形殊异的双侦探模式+不死的“莫里亚蒂”第二可持续拍成系列。另外，可迅速美颜+减肥的神奇药丸请给我来一百颗。'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.get_feature_movie_comment(build_sample['movie'], build_sample['comment_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.43667222]),\n",
       " array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  1.00000000e+00,  4.00000000e+00,\n",
       "          3.40000000e+01,  2.34000000e+02,  8.23463632e-02,\n",
       "         -3.81432291e-03, -2.92093867e-02,  2.69694270e-03,\n",
       "         -3.38714230e-03, -2.49780941e-02, -1.66466133e-02,\n",
       "          2.61597863e-03, -1.70505851e-02,  2.48793910e-02,\n",
       "         -1.09222135e-02, -2.85853715e-03, -3.14414321e-02,\n",
       "         -2.10296739e-03, -3.51920615e-03,  4.26148520e-03,\n",
       "          1.08877800e-02, -6.18221215e-03, -4.90359668e-03,\n",
       "         -2.14716830e-02, -9.43787841e-03,  6.69973263e-04,\n",
       "          4.96503144e-03,  4.73526116e-03, -1.13644634e-02,\n",
       "          1.29223726e-02, -1.29908941e-02, -1.07888899e-02,\n",
       "          4.14193916e-03,  2.30046774e-02, -9.14912530e-03,\n",
       "         -1.56598163e-02,  1.08724329e-03,  4.89036466e-03,\n",
       "         -1.27529576e-02, -1.49558866e-02, -9.65726501e-03,\n",
       "         -3.53389838e-03, -1.11576298e-02, -2.98692803e-02,\n",
       "         -1.20049737e-03, -6.26643705e-03, -2.94414494e-02,\n",
       "          1.33829972e-03,  1.76385628e-02,  1.58157044e-02,\n",
       "         -5.21913583e-03,  2.19828748e-02, -6.31968329e-03,\n",
       "          2.44331463e-03, -2.95701734e-06, -6.07116431e-03,\n",
       "          9.65991230e-03, -1.11789418e-02, -1.24561349e-02,\n",
       "         -3.94975677e-02,  9.81853138e-03,  1.15325452e-03,\n",
       "         -1.85299642e-02, -2.92839197e-02, -3.03025867e-03,\n",
       "          7.60607386e-03, -1.39356160e-02,  2.14122372e-02,\n",
       "          1.55537301e-02, -5.69846829e-04,  3.09105256e-03,\n",
       "         -2.74210391e-03, -1.44534326e-02,  6.49826978e-03,\n",
       "         -5.92318548e-03, -1.19846768e-02, -2.40103866e-03,\n",
       "         -6.11536968e-03,  3.56893733e-03,  1.19423379e-02,\n",
       "          8.54298364e-03,  6.47416732e-03,  2.07352705e-03,\n",
       "          2.85567262e-02,  2.03180390e-02, -3.06676436e-03,\n",
       "          6.24396760e-05, -5.74295523e-03, -1.36061518e-02,\n",
       "         -4.75384266e-03,  4.26970035e-03,  3.25201549e-03,\n",
       "         -1.04110822e-02, -2.02866462e-03,  3.60626870e-05,\n",
       "         -5.75374166e-04, -6.53701721e-04, -1.18853699e-03,\n",
       "          4.62053722e-03,  1.20612879e-02,  2.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  4.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.predict([build_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
